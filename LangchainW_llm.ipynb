{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwI17aP6Asg45vh6QBUw5x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VMadhav007/ML/blob/main/LangchainW_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvrAZPBDUmz8",
        "outputId": "90a1249a-3658-40eb-8340-7ec88feb70b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/dist-packages (0.3.8)\n",
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-0.2.10-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.2.0-py3-none-any.whl.metadata (941 bytes)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.5)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.21.1)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain-mistralai) (0.28.1)\n",
            "Collecting httpx-sse<1,>=0.3.1 (from langchain-mistralai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.52.3)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.32.2)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain-mistralai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->langchain-mistralai) (1.3.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Downloading langchain_mistralai-0.2.10-py3-none-any.whl (16 kB)\n",
            "Downloading langchain_huggingface-0.2.0-py3-none-any.whl (27 kB)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, pypdf, ormsgpack, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, nvidia-cusolver-cu12, langgraph-sdk, dataclasses-json, langgraph-checkpoint, langchain-mistralai, langgraph-prebuilt, langchain-huggingface, langgraph, langchain-community\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.11.0 httpx-sse-0.4.0 langchain-community-0.3.24 langchain-huggingface-0.2.0 langchain-mistralai-0.2.10 langgraph-0.4.8 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 marshmallow-3.26.1 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ormsgpack-1.10.0 pydantic-settings-2.9.1 pypdf-5.6.0 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-core langchain-text-splitters langchain-mistralai langchain-huggingface langchain-community langgraph faiss-cpu python-dotenv pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.documents import Document\n",
        "from typing import List\n",
        "import time"
      ],
      "metadata": {
        "id": "FLfZt9l_VvLM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "# Environment variables\n",
        "MISTRAL_API_KEY = \"api-key\"\n",
        "PDF_PATH = r\"/content/1.pdf\"\n",
        "FAISS_INDEX_PATH = \"faiss_index\""
      ],
      "metadata": {
        "id": "EY2P8oK0W2hD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_pdf():\n",
        "    \"\"\"Load and process the PDF document\"\"\"\n",
        "    print(\"Loading PDF...\")\n",
        "    loader = PyPDFLoader(PDF_PATH)\n",
        "    docs = loader.load()\n",
        "    print(f\"The Length of the Documents is: {len(docs)}\")\n",
        "    #print(f\"{docs[0].page_content[:200]}\\n\")\n",
        "    #print(f\"Metadata: {docs[0].metadata}\")\n",
        "\n",
        "    return docs\n",
        "\n",
        "def create_text_splits(docs):\n",
        "    \"\"\"Create text splits from documents\"\"\"\n",
        "    print(\"Creating text splits...\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        add_start_index=True\n",
        "    )\n",
        "    all_splits = text_splitter.split_documents(docs)\n",
        "    print(f\"Created {len(all_splits)} text chunks\")\n",
        "    return all_splits\n",
        "\n",
        "def setup_vector_store(all_splits):\n",
        "    \"\"\"Set up the vector store with embeddings\"\"\"\n",
        "    print(\"Setting up embeddings and vector store...\")\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "    # Create vector store\n",
        "    vector_store = FAISS.from_documents(all_splits, embeddings, distance_strategy=\"COSINE\")\n",
        "    print(\"FAISS Vector Store created successfully\")\n",
        "\n",
        "    # Save the vector store for future use\n",
        "    try:\n",
        "        vector_store.save_local(FAISS_INDEX_PATH)\n",
        "        print(f\"Vector store saved to {FAISS_INDEX_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not save vector store: {e}\")\n",
        "\n",
        "    return vector_store, embeddings\n",
        "\n",
        "def load_existing_vector_store():\n",
        "    \"\"\"Load existing vector store if available\"\"\"\n",
        "    try:\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "        vector_store = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True, distance_strategy=\"COSINE\")\n",
        "        print(\"Loaded existing vector store\")\n",
        "        return vector_store, embeddings\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load existing vector store: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def setup_mistral_llm():\n",
        "    \"\"\"Initialize Mistral AI LLM\"\"\"\n",
        "    if not MISTRAL_API_KEY:\n",
        "        raise ValueError(\"MISTRAL_API_KEY not found in environment variables\")\n",
        "\n",
        "    llm = ChatMistralAI(\n",
        "        model=\"mistral-large-latest\",\n",
        "        api_key=MISTRAL_API_KEY,\n",
        "        temperature=0.3\n",
        "    )\n",
        "    print(\"Mistral AI LLM initialized\")\n",
        "    return llm\n",
        "\n",
        "def create_rag_chain(vector_store, llm):\n",
        "    \"\"\"Create the RAG chain for question answering\"\"\"\n",
        "\n",
        "    # Create retriever\n",
        "    retriever = vector_store.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\"k\": 4, \"fetch_k\": 8}\n",
        "    )\n",
        "\n",
        "    # Create prompt template\n",
        "    #The {context} and {question} are NOT Python f-string variables. They are LC template placeholders that work\n",
        "    # differently compared to Python String Substitutions.\n",
        "    # They are parsed and substituted during the invocation phase in the code snippets below when the rag_chain object is created.\n",
        "    #\n",
        "    prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
        "    You are an AI assistant that answers questions based on the provided context from a PDF document about AI and Product Management.\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Instructions:\n",
        "    - Answer the question based primarily on the provided context\n",
        "    - If the context doesn't contain enough information, say so clearly\n",
        "    - Provide specific details and examples from the context when available\n",
        "    - Keep your answer comprehensive but concise\n",
        "    - If you reference specific information, try to indicate which part of the document it comes from\n",
        "\n",
        "    Answer:\n",
        "    \"\"\")\n",
        "\n",
        "    def format_docs(docs):\n",
        "        \"\"\"Format retrieved documents for context\"\"\"\n",
        "        formatted = []\n",
        "        for i, doc in enumerate(docs):\n",
        "            page_info = f\"Page {doc.metadata.get('page', 'unknown')}\" if doc.metadata else \"Source unknown\"\n",
        "            formatted.append(f\"[{page_info}]: {doc.page_content}\")\n",
        "        return \"\\n\\n\".join(formatted)\n",
        "\n",
        "    # Create the RAG chain\n",
        "    #Here we use the LC's Chain Composition to send the output of one step as an input to the next step separated by | - Pipe Operator\n",
        "    #More details will be in the README\n",
        "    rag_chain = (\n",
        "        {\n",
        "            \"context\": retriever | format_docs,\n",
        "            \"question\": RunnablePassthrough()\n",
        "        }\n",
        "        | prompt_template\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return rag_chain, retriever\n",
        "\n",
        "def chat_with_pdf(rag_chain, retriever):\n",
        "    \"\"\"Interactive chat function\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🤖 AI PDF Chat Assistant\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"You can now ask questions about your PDF!\")\n",
        "    print(\"Type 'quit', 'exit', or 'bye' to end the conversation.\")\n",
        "    print(\"Type 'help' for available commands.\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            question = input(\"\\n💬 Your question: \").strip()\n",
        "\n",
        "            if not question:\n",
        "                continue\n",
        "\n",
        "            if question.lower() in ['quit', 'exit', 'bye']:\n",
        "                print(\"\\n👋 Goodbye! Thanks for using the AI PDF Chat Assistant!\")\n",
        "                break\n",
        "\n",
        "            if question.lower() == 'help':\n",
        "                print(\"\\n📋 Available commands:\")\n",
        "                print(\"  • Ask any question about the PDF content\")\n",
        "                print(\"  • 'quit', 'exit', 'bye' - End conversation\")\n",
        "                print(\"  • 'help' - Show this help message\")\n",
        "                print(\"  • 'sources' - Show sources for last question\")\n",
        "                continue\n",
        "\n",
        "            if question.lower() == 'sources':\n",
        "                print(\"\\n📚 Retrieving relevant sources...\")\n",
        "                try:\n",
        "                    docs = retriever.get_relevant_documents(question)\n",
        "                    for i, doc in enumerate(docs, 1):\n",
        "                        page_info = f\"Page {doc.metadata.get('page', 'unknown')}\"\n",
        "                        print(f\"\\n--- Source {i} ({page_info}) ---\")\n",
        "                        print(doc.page_content[:300] + \"...\" if len(doc.page_content) > 300 else doc.page_content)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error retrieving sources: {e}\")\n",
        "                continue\n",
        "\n",
        "            print(\"\\n🤔 Thinking...\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Get answer from RAG chain\n",
        "            answer = rag_chain.invoke(question)\n",
        "\n",
        "            response_time = time.time() - start_time\n",
        "\n",
        "            print(f\"\\n🤖 Answer (responded in {response_time:.2f}s):\")\n",
        "            print(\"-\" * 50)\n",
        "            print(answer)\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n👋 Conversation interrupted. Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error: {e}\")\n",
        "            print(\"Please try again with a different question.\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the RAG system\"\"\"\n",
        "    try:\n",
        "        # Try to load existing vector store first\n",
        "        vector_store, embeddings = load_existing_vector_store()\n",
        "\n",
        "        if vector_store is None:\n",
        "            # If no existing vector store, create new one\n",
        "            docs = load_and_process_pdf()\n",
        "            all_splits = create_text_splits(docs)\n",
        "            vector_store, embeddings = setup_vector_store(all_splits)\n",
        "\n",
        "        # Initialize Mistral LLM\n",
        "        llm = setup_mistral_llm()\n",
        "\n",
        "        # Create RAG chain\n",
        "        rag_chain, retriever = create_rag_chain(vector_store, llm)\n",
        "\n",
        "        print(\"\\n✅ System ready!\")\n",
        "\n",
        "        # Test with some example questions\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🧪 TESTING THE SYSTEM\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        test_questions = [\n",
        "            \"What is the impact of AI in Product Management?\",\n",
        "            \"What are the responsibilities of an os?\",\n",
        "            \"How does AI transform product development processes?\"\n",
        "        ]\n",
        "\n",
        "        for i, question in enumerate(test_questions, 1):\n",
        "            print(f\"\\n📝 Test Question {i}: {question}\")\n",
        "            print(\"-\" * 50)\n",
        "            try:\n",
        "                answer = rag_chain.invoke(question)\n",
        "                print(f\"🤖 Answer: {answer[:300]}...\" if len(answer) > 300 else f\"🤖 Answer: {answer}\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error: {e}\")\n",
        "\n",
        "        # Start interactive chat\n",
        "        chat_with_pdf(rag_chain, retriever)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error in main: {e}\")\n",
        "        print(\"Please check your environment variables and file paths.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4LMbS1wZ9ue",
        "outputId": "4160ca95-4ef5-4894-ef17-76558217f620"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded existing vector store\n",
            "Mistral AI LLM initialized\n",
            "\n",
            "✅ System ready!\n",
            "\n",
            "============================================================\n",
            "🧪 TESTING THE SYSTEM\n",
            "============================================================\n",
            "\n",
            "📝 Test Question 1: What is the impact of AI in Product Management?\n",
            "--------------------------------------------------\n",
            "🤖 Answer: The provided context does not contain any information about the impact of AI in Product Management. The document primarily discusses topics related to operating systems, such as the need for an operating system, Direct Memory Access (DMA) structure, and credits for the slides used in a course. There...\n",
            "\n",
            "📝 Test Question 2: What are the responsibilities of an os?\n",
            "--------------------------------------------------\n",
            "🤖 Answer: Based on the provided context, the responsibilities of an operating system (OS) are:\n",
            "\n",
            "1. **Execute User Programs**: The OS is responsible for running user programs and making it easier for users to solve problems (Page 6).\n",
            "\n",
            "2. **User Convenience**: It makes the computer system more convenient to use...\n",
            "\n",
            "📝 Test Question 3: How does AI transform product development processes?\n",
            "--------------------------------------------------\n",
            "🤖 Answer: The provided context does not contain specific information about how AI transforms product development processes. The document primarily discusses operating systems, including their need, program execution models, and credits for the slides used in the course. There is no mention of AI or its impact...\n",
            "\n",
            "============================================================\n",
            "🤖 AI PDF Chat Assistant\n",
            "============================================================\n",
            "You can now ask questions about your PDF!\n",
            "Type 'quit', 'exit', or 'bye' to end the conversation.\n",
            "Type 'help' for available commands.\n",
            "------------------------------------------------------------\n",
            "\n",
            "💬 Your question: help\n",
            "\n",
            "📋 Available commands:\n",
            "  • Ask any question about the PDF content\n",
            "  • 'quit', 'exit', 'bye' - End conversation\n",
            "  • 'help' - Show this help message\n",
            "  • 'sources' - Show sources for last question\n",
            "\n",
            "💬 Your question: sources\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-9dd69176b694>:152: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📚 Retrieving relevant sources...\n",
            "\n",
            "--- Source 1 (Page 5) ---\n",
            "Genesis\n",
            "OPERATING SYSTEMS\n",
            "\n",
            "--- Source 2 (Page 31) ---\n",
            "sureshjamadagni@pes.edu\n",
            "THANK YOU\n",
            "Suresh Jamadagni\n",
            "Department of Computer Science Engineering\n",
            "\n",
            "--- Source 3 (Page 30) ---\n",
            "Direct Memory Access Structure\n",
            "OPERATING SYSTEMS\n",
            "• Used for high-speed I/O devices able to \n",
            "transmit information at close to memory \n",
            "speeds\n",
            "• Device controller transfers blocks of data \n",
            "from buffer storage directly to main memory \n",
            "without CPU intervention\n",
            "• Only one interrupt is generated per block,...\n",
            "\n",
            "--- Source 4 (Page 10) ---\n",
            "What Operating Systems Do\n",
            "OPERATING SYSTEMS\n",
            "n Depends on the point of view user and system\n",
            "n Users want convenience, ease of use and good performance \n",
            "l Don’t care about resource utilization\n",
            "n But shared computer such as mainframe or minicomputer must keep all \n",
            "users happy.\n",
            "n Maximize resource utili...\n",
            "\n",
            "\n",
            "👋 Conversation interrupted. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}